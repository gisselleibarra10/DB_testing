// Code generated by smithy-swift-codegen. DO NOT EDIT!

import ClientRuntime

extension ChimeSdkMediaPipelinesClientTypes.ArtifactsConcatenationConfiguration: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case audio = "Audio"
        case compositedVideo = "CompositedVideo"
        case content = "Content"
        case dataChannel = "DataChannel"
        case meetingEvents = "MeetingEvents"
        case transcriptionMessages = "TranscriptionMessages"
        case video = "Video"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let audio = self.audio {
            try encodeContainer.encode(audio, forKey: .audio)
        }
        if let compositedVideo = self.compositedVideo {
            try encodeContainer.encode(compositedVideo, forKey: .compositedVideo)
        }
        if let content = self.content {
            try encodeContainer.encode(content, forKey: .content)
        }
        if let dataChannel = self.dataChannel {
            try encodeContainer.encode(dataChannel, forKey: .dataChannel)
        }
        if let meetingEvents = self.meetingEvents {
            try encodeContainer.encode(meetingEvents, forKey: .meetingEvents)
        }
        if let transcriptionMessages = self.transcriptionMessages {
            try encodeContainer.encode(transcriptionMessages, forKey: .transcriptionMessages)
        }
        if let video = self.video {
            try encodeContainer.encode(video, forKey: .video)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let audioDecoded = try containerValues.decodeIfPresent(ChimeSdkMediaPipelinesClientTypes.AudioConcatenationConfiguration.self, forKey: .audio)
        audio = audioDecoded
        let videoDecoded = try containerValues.decodeIfPresent(ChimeSdkMediaPipelinesClientTypes.VideoConcatenationConfiguration.self, forKey: .video)
        video = videoDecoded
        let contentDecoded = try containerValues.decodeIfPresent(ChimeSdkMediaPipelinesClientTypes.ContentConcatenationConfiguration.self, forKey: .content)
        content = contentDecoded
        let dataChannelDecoded = try containerValues.decodeIfPresent(ChimeSdkMediaPipelinesClientTypes.DataChannelConcatenationConfiguration.self, forKey: .dataChannel)
        dataChannel = dataChannelDecoded
        let transcriptionMessagesDecoded = try containerValues.decodeIfPresent(ChimeSdkMediaPipelinesClientTypes.TranscriptionMessagesConcatenationConfiguration.self, forKey: .transcriptionMessages)
        transcriptionMessages = transcriptionMessagesDecoded
        let meetingEventsDecoded = try containerValues.decodeIfPresent(ChimeSdkMediaPipelinesClientTypes.MeetingEventsConcatenationConfiguration.self, forKey: .meetingEvents)
        meetingEvents = meetingEventsDecoded
        let compositedVideoDecoded = try containerValues.decodeIfPresent(ChimeSdkMediaPipelinesClientTypes.CompositedVideoConcatenationConfiguration.self, forKey: .compositedVideo)
        compositedVideo = compositedVideoDecoded
    }
}
