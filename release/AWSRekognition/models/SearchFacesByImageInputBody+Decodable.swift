// Code generated by smithy-swift-codegen. DO NOT EDIT!

import ClientRuntime

struct SearchFacesByImageInputBody: Swift.Equatable {
    let collectionId: Swift.String?
    let image: RekognitionClientTypes.Image?
    let maxFaces: Swift.Int?
    let faceMatchThreshold: Swift.Float?
    let qualityFilter: RekognitionClientTypes.QualityFilter?
}

extension SearchFacesByImageInputBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case collectionId = "CollectionId"
        case faceMatchThreshold = "FaceMatchThreshold"
        case image = "Image"
        case maxFaces = "MaxFaces"
        case qualityFilter = "QualityFilter"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let collectionIdDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .collectionId)
        collectionId = collectionIdDecoded
        let imageDecoded = try containerValues.decodeIfPresent(RekognitionClientTypes.Image.self, forKey: .image)
        image = imageDecoded
        let maxFacesDecoded = try containerValues.decodeIfPresent(Swift.Int.self, forKey: .maxFaces)
        maxFaces = maxFacesDecoded
        let faceMatchThresholdDecoded = try containerValues.decodeIfPresent(Swift.Float.self, forKey: .faceMatchThreshold)
        faceMatchThreshold = faceMatchThresholdDecoded
        let qualityFilterDecoded = try containerValues.decodeIfPresent(RekognitionClientTypes.QualityFilter.self, forKey: .qualityFilter)
        qualityFilter = qualityFilterDecoded
    }
}
