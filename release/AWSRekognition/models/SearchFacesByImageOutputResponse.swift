// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct SearchFacesByImageOutputResponse: Swift.Equatable {
    /// An array of faces that match the input face, along with the confidence in the match.
    public var faceMatches: [RekognitionClientTypes.FaceMatch]?
    /// Version number of the face detection model associated with the input collection (CollectionId).
    public var faceModelVersion: Swift.String?
    /// The bounding box around the face in the input image that Amazon Rekognition used for the search.
    public var searchedFaceBoundingBox: RekognitionClientTypes.BoundingBox?
    /// The level of confidence that the searchedFaceBoundingBox, contains a face.
    public var searchedFaceConfidence: Swift.Float?

    public init (
        faceMatches: [RekognitionClientTypes.FaceMatch]? = nil,
        faceModelVersion: Swift.String? = nil,
        searchedFaceBoundingBox: RekognitionClientTypes.BoundingBox? = nil,
        searchedFaceConfidence: Swift.Float? = nil
    )
    {
        self.faceMatches = faceMatches
        self.faceModelVersion = faceModelVersion
        self.searchedFaceBoundingBox = searchedFaceBoundingBox
        self.searchedFaceConfidence = searchedFaceConfidence
    }
}
