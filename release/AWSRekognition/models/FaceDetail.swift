// Code generated by smithy-swift-codegen. DO NOT EDIT!



extension RekognitionClientTypes {
    /// Structure containing attributes of the face that the algorithm detected. A FaceDetail object contains either the default facial attributes or all facial attributes. The default attributes are BoundingBox, Confidence, Landmarks, Pose, and Quality. [GetFaceDetection] is the only Amazon Rekognition Video stored video operation that can return a FaceDetail object with all attributes. To specify which attributes to return, use the FaceAttributes input parameter for [StartFaceDetection]. The following Amazon Rekognition Video operations return only the default attributes. The corresponding Start operations don't have a FaceAttributes input parameter.
    ///
    /// * GetCelebrityRecognition
    ///
    /// * GetPersonTracking
    ///
    /// * GetFaceSearch
    ///
    ///
    /// The Amazon Rekognition Image [DetectFaces] and [IndexFaces] operations can return all facial attributes. To specify which attributes to return, use the Attributes input parameter for DetectFaces. For IndexFaces, use the DetectAttributes input parameter.
    public struct FaceDetail: Swift.Equatable {
        /// The estimated age range, in years, for the face. Low represents the lowest estimated age and High represents the highest estimated age.
        public var ageRange: RekognitionClientTypes.AgeRange?
        /// Indicates whether or not the face has a beard, and the confidence level in the determination.
        public var beard: RekognitionClientTypes.Beard?
        /// Bounding box of the face. Default attribute.
        public var boundingBox: RekognitionClientTypes.BoundingBox?
        /// Confidence level that the bounding box contains a face (and not a different object such as a tree). Default attribute.
        public var confidence: Swift.Float?
        /// The emotions that appear to be expressed on the face, and the confidence level in the determination. The API is only making a determination of the physical appearance of a person's face. It is not a determination of the personâ€™s internal emotional state and should not be used in such a way. For example, a person pretending to have a sad face might not be sad emotionally.
        public var emotions: [RekognitionClientTypes.Emotion]?
        /// Indicates whether or not the face is wearing eye glasses, and the confidence level in the determination.
        public var eyeglasses: RekognitionClientTypes.Eyeglasses?
        /// Indicates whether or not the eyes on the face are open, and the confidence level in the determination.
        public var eyesOpen: RekognitionClientTypes.EyeOpen?
        /// The predicted gender of a detected face.
        public var gender: RekognitionClientTypes.Gender?
        /// Indicates the location of landmarks on the face. Default attribute.
        public var landmarks: [RekognitionClientTypes.Landmark]?
        /// Indicates whether or not the mouth on the face is open, and the confidence level in the determination.
        public var mouthOpen: RekognitionClientTypes.MouthOpen?
        /// Indicates whether or not the face has a mustache, and the confidence level in the determination.
        public var mustache: RekognitionClientTypes.Mustache?
        /// Indicates the pose of the face as determined by its pitch, roll, and yaw. Default attribute.
        public var pose: RekognitionClientTypes.Pose?
        /// Identifies image brightness and sharpness. Default attribute.
        public var quality: RekognitionClientTypes.ImageQuality?
        /// Indicates whether or not the face is smiling, and the confidence level in the determination.
        public var smile: RekognitionClientTypes.Smile?
        /// Indicates whether or not the face is wearing sunglasses, and the confidence level in the determination.
        public var sunglasses: RekognitionClientTypes.Sunglasses?

        public init (
            ageRange: RekognitionClientTypes.AgeRange? = nil,
            beard: RekognitionClientTypes.Beard? = nil,
            boundingBox: RekognitionClientTypes.BoundingBox? = nil,
            confidence: Swift.Float? = nil,
            emotions: [RekognitionClientTypes.Emotion]? = nil,
            eyeglasses: RekognitionClientTypes.Eyeglasses? = nil,
            eyesOpen: RekognitionClientTypes.EyeOpen? = nil,
            gender: RekognitionClientTypes.Gender? = nil,
            landmarks: [RekognitionClientTypes.Landmark]? = nil,
            mouthOpen: RekognitionClientTypes.MouthOpen? = nil,
            mustache: RekognitionClientTypes.Mustache? = nil,
            pose: RekognitionClientTypes.Pose? = nil,
            quality: RekognitionClientTypes.ImageQuality? = nil,
            smile: RekognitionClientTypes.Smile? = nil,
            sunglasses: RekognitionClientTypes.Sunglasses? = nil
        )
        {
            self.ageRange = ageRange
            self.beard = beard
            self.boundingBox = boundingBox
            self.confidence = confidence
            self.emotions = emotions
            self.eyeglasses = eyeglasses
            self.eyesOpen = eyesOpen
            self.gender = gender
            self.landmarks = landmarks
            self.mouthOpen = mouthOpen
            self.mustache = mustache
            self.pose = pose
            self.quality = quality
            self.smile = smile
            self.sunglasses = sunglasses
        }
    }

}
