// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct DetectModerationLabelsInput: Swift.Equatable {
    /// Sets up the configuration for human evaluation, including the FlowDefinition the image will be sent to.
    public var humanLoopConfig: RekognitionClientTypes.HumanLoopConfig?
    /// The input image as base64-encoded bytes or an S3 object. If you use the AWS CLI to call Amazon Rekognition operations, passing base64-encoded image bytes is not supported. If you are using an AWS SDK to call Amazon Rekognition, you might not need to base64-encode image bytes passed using the Bytes field. For more information, see Images in the Amazon Rekognition developer guide.
    /// This member is required.
    public var image: RekognitionClientTypes.Image?
    /// Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with a confidence level lower than this specified value. If you don't specify MinConfidence, the operation returns labels with confidence values greater than or equal to 50 percent.
    public var minConfidence: Swift.Float?

    public init (
        humanLoopConfig: RekognitionClientTypes.HumanLoopConfig? = nil,
        image: RekognitionClientTypes.Image? = nil,
        minConfidence: Swift.Float? = nil
    )
    {
        self.humanLoopConfig = humanLoopConfig
        self.image = image
        self.minConfidence = minConfidence
    }
}
