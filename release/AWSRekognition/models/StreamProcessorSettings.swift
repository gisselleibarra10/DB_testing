// Code generated by smithy-swift-codegen. DO NOT EDIT!



extension RekognitionClientTypes {
    /// Input parameters used in a streaming video analyzed by a Amazon Rekognition stream processor. You can use FaceSearch to recognize faces in a streaming video, or you can use ConnectedHome to detect labels.
    public struct StreamProcessorSettings: Swift.Equatable {
        /// Label detection settings to use on a streaming video. Defining the settings is required in the request parameter for [CreateStreamProcessor]. Including this setting in the CreateStreamProcessor request enables you to use the stream processor for label detection. You can then select what you want the stream processor to detect, such as people or pets. When the stream processor has started, one notification is sent for each object class specified. For example, if packages and pets are selected, one SNS notification is published the first time a package is detected and one SNS notification is published the first time a pet is detected, as well as an end-of-session summary.
        public var connectedHome: RekognitionClientTypes.ConnectedHomeSettings?
        /// Face search settings to use on a streaming video.
        public var faceSearch: RekognitionClientTypes.FaceSearchSettings?

        public init (
            connectedHome: RekognitionClientTypes.ConnectedHomeSettings? = nil,
            faceSearch: RekognitionClientTypes.FaceSearchSettings? = nil
        )
        {
            self.connectedHome = connectedHome
            self.faceSearch = faceSearch
        }
    }

}
