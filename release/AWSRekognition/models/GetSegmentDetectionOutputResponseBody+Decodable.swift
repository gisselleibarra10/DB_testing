// Code generated by smithy-swift-codegen. DO NOT EDIT!

import ClientRuntime

struct GetSegmentDetectionOutputResponseBody: Swift.Equatable {
    let jobStatus: RekognitionClientTypes.VideoJobStatus?
    let statusMessage: Swift.String?
    let videoMetadata: [RekognitionClientTypes.VideoMetadata]?
    let audioMetadata: [RekognitionClientTypes.AudioMetadata]?
    let nextToken: Swift.String?
    let segments: [RekognitionClientTypes.SegmentDetection]?
    let selectedSegmentTypes: [RekognitionClientTypes.SegmentTypeInfo]?
}

extension GetSegmentDetectionOutputResponseBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case audioMetadata = "AudioMetadata"
        case jobStatus = "JobStatus"
        case nextToken = "NextToken"
        case segments = "Segments"
        case selectedSegmentTypes = "SelectedSegmentTypes"
        case statusMessage = "StatusMessage"
        case videoMetadata = "VideoMetadata"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let jobStatusDecoded = try containerValues.decodeIfPresent(RekognitionClientTypes.VideoJobStatus.self, forKey: .jobStatus)
        jobStatus = jobStatusDecoded
        let statusMessageDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .statusMessage)
        statusMessage = statusMessageDecoded
        let videoMetadataContainer = try containerValues.decodeIfPresent([RekognitionClientTypes.VideoMetadata?].self, forKey: .videoMetadata)
        var videoMetadataDecoded0:[RekognitionClientTypes.VideoMetadata]? = nil
        if let videoMetadataContainer = videoMetadataContainer {
            videoMetadataDecoded0 = [RekognitionClientTypes.VideoMetadata]()
            for structure0 in videoMetadataContainer {
                if let structure0 = structure0 {
                    videoMetadataDecoded0?.append(structure0)
                }
            }
        }
        videoMetadata = videoMetadataDecoded0
        let audioMetadataContainer = try containerValues.decodeIfPresent([RekognitionClientTypes.AudioMetadata?].self, forKey: .audioMetadata)
        var audioMetadataDecoded0:[RekognitionClientTypes.AudioMetadata]? = nil
        if let audioMetadataContainer = audioMetadataContainer {
            audioMetadataDecoded0 = [RekognitionClientTypes.AudioMetadata]()
            for structure0 in audioMetadataContainer {
                if let structure0 = structure0 {
                    audioMetadataDecoded0?.append(structure0)
                }
            }
        }
        audioMetadata = audioMetadataDecoded0
        let nextTokenDecoded = try containerValues.decodeIfPresent(Swift.String.self, forKey: .nextToken)
        nextToken = nextTokenDecoded
        let segmentsContainer = try containerValues.decodeIfPresent([RekognitionClientTypes.SegmentDetection?].self, forKey: .segments)
        var segmentsDecoded0:[RekognitionClientTypes.SegmentDetection]? = nil
        if let segmentsContainer = segmentsContainer {
            segmentsDecoded0 = [RekognitionClientTypes.SegmentDetection]()
            for structure0 in segmentsContainer {
                if let structure0 = structure0 {
                    segmentsDecoded0?.append(structure0)
                }
            }
        }
        segments = segmentsDecoded0
        let selectedSegmentTypesContainer = try containerValues.decodeIfPresent([RekognitionClientTypes.SegmentTypeInfo?].self, forKey: .selectedSegmentTypes)
        var selectedSegmentTypesDecoded0:[RekognitionClientTypes.SegmentTypeInfo]? = nil
        if let selectedSegmentTypesContainer = selectedSegmentTypesContainer {
            selectedSegmentTypesDecoded0 = [RekognitionClientTypes.SegmentTypeInfo]()
            for structure0 in selectedSegmentTypesContainer {
                if let structure0 = structure0 {
                    selectedSegmentTypesDecoded0?.append(structure0)
                }
            }
        }
        selectedSegmentTypes = selectedSegmentTypesDecoded0
    }
}
