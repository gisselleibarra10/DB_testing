// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct GetPersonTrackingOutputResponse: Swift.Equatable {
    /// The current status of the person tracking job.
    public var jobStatus: RekognitionClientTypes.VideoJobStatus?
    /// If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of persons.
    public var nextToken: Swift.String?
    /// An array of the persons detected in the video and the time(s) their path was tracked throughout the video. An array element will exist for each time a person's path is tracked.
    public var persons: [RekognitionClientTypes.PersonDetection]?
    /// If the job fails, StatusMessage provides a descriptive error message.
    public var statusMessage: Swift.String?
    /// Information about a video that Amazon Rekognition Video analyzed. Videometadata is returned in every page of paginated responses from a Amazon Rekognition Video operation.
    public var videoMetadata: RekognitionClientTypes.VideoMetadata?

    public init (
        jobStatus: RekognitionClientTypes.VideoJobStatus? = nil,
        nextToken: Swift.String? = nil,
        persons: [RekognitionClientTypes.PersonDetection]? = nil,
        statusMessage: Swift.String? = nil,
        videoMetadata: RekognitionClientTypes.VideoMetadata? = nil
    )
    {
        self.jobStatus = jobStatus
        self.nextToken = nextToken
        self.persons = persons
        self.statusMessage = statusMessage
        self.videoMetadata = videoMetadata
    }
}
