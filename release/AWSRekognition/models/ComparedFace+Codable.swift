// Code generated by smithy-swift-codegen. DO NOT EDIT!

import ClientRuntime

extension RekognitionClientTypes.ComparedFace: Swift.Codable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case boundingBox = "BoundingBox"
        case confidence = "Confidence"
        case emotions = "Emotions"
        case landmarks = "Landmarks"
        case pose = "Pose"
        case quality = "Quality"
        case smile = "Smile"
    }

    public func encode(to encoder: Swift.Encoder) throws {
        var encodeContainer = encoder.container(keyedBy: CodingKeys.self)
        if let boundingBox = self.boundingBox {
            try encodeContainer.encode(boundingBox, forKey: .boundingBox)
        }
        if let confidence = self.confidence {
            try encodeContainer.encode(confidence, forKey: .confidence)
        }
        if let emotions = emotions {
            var emotionsContainer = encodeContainer.nestedUnkeyedContainer(forKey: .emotions)
            for emotions0 in emotions {
                try emotionsContainer.encode(emotions0)
            }
        }
        if let landmarks = landmarks {
            var landmarksContainer = encodeContainer.nestedUnkeyedContainer(forKey: .landmarks)
            for landmarks0 in landmarks {
                try landmarksContainer.encode(landmarks0)
            }
        }
        if let pose = self.pose {
            try encodeContainer.encode(pose, forKey: .pose)
        }
        if let quality = self.quality {
            try encodeContainer.encode(quality, forKey: .quality)
        }
        if let smile = self.smile {
            try encodeContainer.encode(smile, forKey: .smile)
        }
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let boundingBoxDecoded = try containerValues.decodeIfPresent(RekognitionClientTypes.BoundingBox.self, forKey: .boundingBox)
        boundingBox = boundingBoxDecoded
        let confidenceDecoded = try containerValues.decodeIfPresent(Swift.Float.self, forKey: .confidence)
        confidence = confidenceDecoded
        let landmarksContainer = try containerValues.decodeIfPresent([RekognitionClientTypes.Landmark?].self, forKey: .landmarks)
        var landmarksDecoded0:[RekognitionClientTypes.Landmark]? = nil
        if let landmarksContainer = landmarksContainer {
            landmarksDecoded0 = [RekognitionClientTypes.Landmark]()
            for structure0 in landmarksContainer {
                if let structure0 = structure0 {
                    landmarksDecoded0?.append(structure0)
                }
            }
        }
        landmarks = landmarksDecoded0
        let poseDecoded = try containerValues.decodeIfPresent(RekognitionClientTypes.Pose.self, forKey: .pose)
        pose = poseDecoded
        let qualityDecoded = try containerValues.decodeIfPresent(RekognitionClientTypes.ImageQuality.self, forKey: .quality)
        quality = qualityDecoded
        let emotionsContainer = try containerValues.decodeIfPresent([RekognitionClientTypes.Emotion?].self, forKey: .emotions)
        var emotionsDecoded0:[RekognitionClientTypes.Emotion]? = nil
        if let emotionsContainer = emotionsContainer {
            emotionsDecoded0 = [RekognitionClientTypes.Emotion]()
            for structure0 in emotionsContainer {
                if let structure0 = structure0 {
                    emotionsDecoded0?.append(structure0)
                }
            }
        }
        emotions = emotionsDecoded0
        let smileDecoded = try containerValues.decodeIfPresent(RekognitionClientTypes.Smile.self, forKey: .smile)
        smile = smileDecoded
    }
}
