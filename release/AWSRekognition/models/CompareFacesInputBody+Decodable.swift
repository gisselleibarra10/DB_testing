// Code generated by smithy-swift-codegen. DO NOT EDIT!

import ClientRuntime

struct CompareFacesInputBody: Swift.Equatable {
    let sourceImage: RekognitionClientTypes.Image?
    let targetImage: RekognitionClientTypes.Image?
    let similarityThreshold: Swift.Float?
    let qualityFilter: RekognitionClientTypes.QualityFilter?
}

extension CompareFacesInputBody: Swift.Decodable {
    enum CodingKeys: Swift.String, Swift.CodingKey {
        case qualityFilter = "QualityFilter"
        case similarityThreshold = "SimilarityThreshold"
        case sourceImage = "SourceImage"
        case targetImage = "TargetImage"
    }

    public init (from decoder: Swift.Decoder) throws {
        let containerValues = try decoder.container(keyedBy: CodingKeys.self)
        let sourceImageDecoded = try containerValues.decodeIfPresent(RekognitionClientTypes.Image.self, forKey: .sourceImage)
        sourceImage = sourceImageDecoded
        let targetImageDecoded = try containerValues.decodeIfPresent(RekognitionClientTypes.Image.self, forKey: .targetImage)
        targetImage = targetImageDecoded
        let similarityThresholdDecoded = try containerValues.decodeIfPresent(Swift.Float.self, forKey: .similarityThreshold)
        similarityThreshold = similarityThresholdDecoded
        let qualityFilterDecoded = try containerValues.decodeIfPresent(RekognitionClientTypes.QualityFilter.self, forKey: .qualityFilter)
        qualityFilter = qualityFilterDecoded
    }
}
