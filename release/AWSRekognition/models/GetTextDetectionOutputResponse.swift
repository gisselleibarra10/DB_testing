// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct GetTextDetectionOutputResponse: Swift.Equatable {
    /// Current status of the text detection job.
    public var jobStatus: RekognitionClientTypes.VideoJobStatus?
    /// If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of text.
    public var nextToken: Swift.String?
    /// If the job fails, StatusMessage provides a descriptive error message.
    public var statusMessage: Swift.String?
    /// An array of text detected in the video. Each element contains the detected text, the time in milliseconds from the start of the video that the text was detected, and where it was detected on the screen.
    public var textDetections: [RekognitionClientTypes.TextDetectionResult]?
    /// Version number of the text detection model that was used to detect text.
    public var textModelVersion: Swift.String?
    /// Information about a video that Amazon Rekognition analyzed. Videometadata is returned in every page of paginated responses from a Amazon Rekognition video operation.
    public var videoMetadata: RekognitionClientTypes.VideoMetadata?

    public init (
        jobStatus: RekognitionClientTypes.VideoJobStatus? = nil,
        nextToken: Swift.String? = nil,
        statusMessage: Swift.String? = nil,
        textDetections: [RekognitionClientTypes.TextDetectionResult]? = nil,
        textModelVersion: Swift.String? = nil,
        videoMetadata: RekognitionClientTypes.VideoMetadata? = nil
    )
    {
        self.jobStatus = jobStatus
        self.nextToken = nextToken
        self.statusMessage = statusMessage
        self.textDetections = textDetections
        self.textModelVersion = textModelVersion
        self.videoMetadata = videoMetadata
    }
}
