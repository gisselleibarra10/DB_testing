// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct GetLabelDetectionOutputResponse: Swift.Equatable {
    /// The current status of the label detection job.
    public var jobStatus: RekognitionClientTypes.VideoJobStatus?
    /// Version number of the label detection model that was used to detect labels.
    public var labelModelVersion: Swift.String?
    /// An array of labels detected in the video. Each element contains the detected label and the time, in milliseconds from the start of the video, that the label was detected.
    public var labels: [RekognitionClientTypes.LabelDetection]?
    /// If the response is truncated, Amazon Rekognition Video returns this token that you can use in the subsequent request to retrieve the next set of labels.
    public var nextToken: Swift.String?
    /// If the job fails, StatusMessage provides a descriptive error message.
    public var statusMessage: Swift.String?
    /// Information about a video that Amazon Rekognition Video analyzed. Videometadata is returned in every page of paginated responses from a Amazon Rekognition video operation.
    public var videoMetadata: RekognitionClientTypes.VideoMetadata?

    public init (
        jobStatus: RekognitionClientTypes.VideoJobStatus? = nil,
        labelModelVersion: Swift.String? = nil,
        labels: [RekognitionClientTypes.LabelDetection]? = nil,
        nextToken: Swift.String? = nil,
        statusMessage: Swift.String? = nil,
        videoMetadata: RekognitionClientTypes.VideoMetadata? = nil
    )
    {
        self.jobStatus = jobStatus
        self.labelModelVersion = labelModelVersion
        self.labels = labels
        self.nextToken = nextToken
        self.statusMessage = statusMessage
        self.videoMetadata = videoMetadata
    }
}
