// Code generated by smithy-swift-codegen. DO NOT EDIT!



extension RekognitionClientTypes {
    /// Provides face metadata for target image faces that are analyzed by CompareFaces and RecognizeCelebrities.
    public struct ComparedFace: Swift.Equatable {
        /// Bounding box of the face.
        public var boundingBox: RekognitionClientTypes.BoundingBox?
        /// Level of confidence that what the bounding box contains is a face.
        public var confidence: Swift.Float?
        /// The emotions that appear to be expressed on the face, and the confidence level in the determination. Valid values include "Happy", "Sad", "Angry", "Confused", "Disgusted", "Surprised", "Calm", "Unknown", and "Fear".
        public var emotions: [RekognitionClientTypes.Emotion]?
        /// An array of facial landmarks.
        public var landmarks: [RekognitionClientTypes.Landmark]?
        /// Indicates the pose of the face as determined by its pitch, roll, and yaw.
        public var pose: RekognitionClientTypes.Pose?
        /// Identifies face image brightness and sharpness.
        public var quality: RekognitionClientTypes.ImageQuality?
        /// Indicates whether or not the face is smiling, and the confidence level in the determination.
        public var smile: RekognitionClientTypes.Smile?

        public init (
            boundingBox: RekognitionClientTypes.BoundingBox? = nil,
            confidence: Swift.Float? = nil,
            emotions: [RekognitionClientTypes.Emotion]? = nil,
            landmarks: [RekognitionClientTypes.Landmark]? = nil,
            pose: RekognitionClientTypes.Pose? = nil,
            quality: RekognitionClientTypes.ImageQuality? = nil,
            smile: RekognitionClientTypes.Smile? = nil
        )
        {
            self.boundingBox = boundingBox
            self.confidence = confidence
            self.emotions = emotions
            self.landmarks = landmarks
            self.pose = pose
            self.quality = quality
            self.smile = smile
        }
    }

}
