// Code generated by smithy-swift-codegen. DO NOT EDIT!



public struct StartMedicalStreamTranscriptionInput: Swift.Equatable {
    /// Represents the audio stream from your application to Amazon Transcribe.
    /// This member is required.
    public var audioStream: TranscribeStreamingClientTypes.AudioStream?
    /// Set this field to PHI to identify personal health information in the transcription output.
    public var contentIdentificationType: TranscribeStreamingClientTypes.MedicalContentIdentificationType?
    /// When true, instructs Amazon Transcribe Medical to process each audio channel separately and then merge the transcription output of each channel into a single transcription. Amazon Transcribe Medical also produces a transcription of each item. An item includes the start time, end time, and any alternative transcriptions. You can't set both ShowSpeakerLabel and EnableChannelIdentification in the same request. If you set both, your request returns a BadRequestException.
    public var enableChannelIdentification: Swift.Bool
    /// Indicates the source language used in the input audio stream. For Amazon Transcribe Medical, this is US English (en-US).
    /// This member is required.
    public var languageCode: TranscribeStreamingClientTypes.LanguageCode?
    /// The encoding used for the input audio.
    /// This member is required.
    public var mediaEncoding: TranscribeStreamingClientTypes.MediaEncoding?
    /// The sample rate of the input audio (in Hertz). Amazon Transcribe medical supports a range from 16,000 Hz to 48,000 Hz. Note that the sample rate you specify must match that of your audio.
    /// This member is required.
    public var mediaSampleRateHertz: Swift.Int?
    /// The number of channels that are in your audio stream.
    public var numberOfChannels: Swift.Int?
    /// Optional. An identifier for the transcription session. If you don't provide a session ID, Amazon Transcribe generates one for you and returns it in the response.
    public var sessionId: Swift.String?
    /// When true, enables speaker identification in your real-time stream.
    public var showSpeakerLabel: Swift.Bool
    /// The medical specialty of the clinician or provider.
    /// This member is required.
    public var specialty: TranscribeStreamingClientTypes.Specialty?
    /// The type of input audio. Choose DICTATION for a provider dictating patient notes. Choose CONVERSATION for a dialogue between a patient and one or more medical professionanls.
    /// This member is required.
    public var type: TranscribeStreamingClientTypes.ModelType?
    /// The name of the medical custom vocabulary to use when processing the real-time stream.
    public var vocabularyName: Swift.String?

    public init (
        audioStream: TranscribeStreamingClientTypes.AudioStream? = nil,
        contentIdentificationType: TranscribeStreamingClientTypes.MedicalContentIdentificationType? = nil,
        enableChannelIdentification: Swift.Bool = false,
        languageCode: TranscribeStreamingClientTypes.LanguageCode? = nil,
        mediaEncoding: TranscribeStreamingClientTypes.MediaEncoding? = nil,
        mediaSampleRateHertz: Swift.Int? = nil,
        numberOfChannels: Swift.Int? = nil,
        sessionId: Swift.String? = nil,
        showSpeakerLabel: Swift.Bool = false,
        specialty: TranscribeStreamingClientTypes.Specialty? = nil,
        type: TranscribeStreamingClientTypes.ModelType? = nil,
        vocabularyName: Swift.String? = nil
    )
    {
        self.audioStream = audioStream
        self.contentIdentificationType = contentIdentificationType
        self.enableChannelIdentification = enableChannelIdentification
        self.languageCode = languageCode
        self.mediaEncoding = mediaEncoding
        self.mediaSampleRateHertz = mediaSampleRateHertz
        self.numberOfChannels = numberOfChannels
        self.sessionId = sessionId
        self.showSpeakerLabel = showSpeakerLabel
        self.specialty = specialty
        self.type = type
        self.vocabularyName = vocabularyName
    }
}
